{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_bootcamp_dphi.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNF8E8vEDKJVjQnRVqWixYx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUPaHf_Gnfif"
      },
      "source": [
        "# NLP Bootcamp by Dphi\n",
        "Instructor: Dipanjan Sarkar\n",
        "\n",
        "[Github Repository](https://bit.ly/nlp101_ds) consisting code samples and slide deck.\n",
        "\n",
        "[Bootcamp link](https://bootcamp.dphi.tech/getting-started-with-natural-language-processing/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTpJA7tl1ws-"
      },
      "source": [
        "## Module 1 - The what and why of NLP ?\n",
        "\n",
        "Natural Language Processing or NLP is a field of Artificial Intelligence that gives the machines the ability to read, understand and derive meaning from human languages.\n",
        "\n",
        "**Applications of NLP**\n",
        "- Text Classification & Clustering\n",
        "- Sentiment Analysis\n",
        "- Information retrieval\n",
        "- Machine Translation\n",
        "- Information extraction\n",
        "- Question Answering (ChatBot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POhKfP_N9fzf"
      },
      "source": [
        "## Module 2 - NLP Workflow and Text wrangling\n",
        "\n",
        "A NLP workflow consists of following key steps:\n",
        "\n",
        "> *Text Document --> Text Pre-processing --> Text parsing & exploratory data analysis --> Text representation & feature engineering --> modelling & pattern minning --> Evaluation & Deployment*\n",
        "\n",
        "**Text Wrangling** is a pre-processing of text data to remove unnecessary keywords such as HTML Tags, whitespace, special characters, stop words etc. It may also involves advance pre-processing such as tokenization, stemming, lemmatization, contraction etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MEufAP1nbUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7ca970-a9b1-4891-9d46-11fd4c738acc"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaYhgYkCjlwh"
      },
      "source": [
        "#### Case Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXOABkfwnmod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33474996-71f3-4503-9e4b-9c233e7560a8"
      },
      "source": [
        "text = 'The quick brown fox jumped over The Big Dog'\n",
        "print(text)\n",
        "print(text.lower())\n",
        "print(text.upper())\n",
        "print(text.title())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quick brown fox jumped over The Big Dog\n",
            "the quick brown fox jumped over the big dog\n",
            "THE QUICK BROWN FOX JUMPED OVER THE BIG DOG\n",
            "The Quick Brown Fox Jumped Over The Big Dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad8leQd9j7nz"
      },
      "source": [
        "#### Tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgSfpqrKj093",
        "outputId": "469b0818-3a5d-44da-ccac-8e4ca3b1c5ad"
      },
      "source": [
        "sample_text = (\"US unveils world's most powerful supercomputer, beats China. \" \n",
        "               \"The US has unveiled the world's most powerful supercomputer called 'Summit', \" \n",
        "               \"beating the previous record-holder China's Sunway TaihuLight. With a peak performance \"\n",
        "               \"of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, \"\n",
        "               \"which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, \"\n",
        "               \"which reportedly take up the size of two tennis courts.\")\n",
        "nltk.sent_tokenize(sample_text)  # tokenize as sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"US unveils world's most powerful supercomputer, beats China.\",\n",
              " \"The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight.\",\n",
              " 'With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second.',\n",
              " 'Summit has 4,608 servers, which reportedly take up the size of two tennis courts.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL6UgrQNkIMq",
        "outputId": "20c9d9d4-6935-41b9-a07b-8a3d4661802f"
      },
      "source": [
        "print(nltk.word_tokenize(sample_text))  # tokenize as word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['US', 'unveils', 'world', \"'s\", 'most', 'powerful', 'supercomputer', ',', 'beats', 'China', '.', 'The', 'US', 'has', 'unveiled', 'the', 'world', \"'s\", 'most', 'powerful', 'supercomputer', 'called', \"'Summit\", \"'\", ',', 'beating', 'the', 'previous', 'record-holder', 'China', \"'s\", 'Sunway', 'TaihuLight', '.', 'With', 'a', 'peak', 'performance', 'of', '200,000', 'trillion', 'calculations', 'per', 'second', ',', 'it', 'is', 'over', 'twice', 'as', 'fast', 'as', 'Sunway', 'TaihuLight', ',', 'which', 'is', 'capable', 'of', '93,000', 'trillion', 'calculations', 'per', 'second', '.', 'Summit', 'has', '4,608', 'servers', ',', 'which', 'reportedly', 'take', 'up', 'the', 'size', 'of', 'two', 'tennis', 'courts', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hChlApfzkdAO"
      },
      "source": [
        "#### Removing HTML tags\n",
        "\n",
        "Text content parsed from a web page can be cleaned using beautiful soup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJrrpPyWkTrz",
        "outputId": "94d9f566-3351-4414-bc51-3e37ed24fa42"
      },
      "source": [
        "# Get HTML content from a web URL\n",
        "import requests\n",
        "\n",
        "data = requests.get('https://www.nltk.org/')\n",
        "content = data.text[3810:5902]\n",
        "print(content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<p>NLTK is a leading platform for building Python programs to work with human language data.\n",
            "It provides easy-to-use interfaces to <a class=\"reference external\" href=\"https://www.nltk.org/nltk_data/\">over 50 corpora and lexical\n",
            "resources</a> such as WordNet,\n",
            "along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,\n",
            "wrappers for industrial-strength NLP libraries,\n",
            "and an active <a class=\"reference external\" href=\"https://groups.google.com/group/nltk-users\">discussion forum</a>.</p>\n",
            "<p>Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,\n",
            "NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.\n",
            "NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.</p>\n",
            "<p>NLTK has been called ‚Äúa wonderful tool for teaching, and working in, computational linguistics using Python,‚Äù\n",
            "and ‚Äúan amazing library to play with natural language.‚Äù</p>\n",
            "<p><a class=\"reference external\" href=\"https://www.nltk.org/book\">Natural Language Processing with Python</a> provides a practical\n",
            "introduction to programming for language processing.\n",
            "Written by the creators of NLTK, it guides the reader through the fundamentals\n",
            "of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,\n",
            "and more.\n",
            "The online version of the book has been been updated for Python 3 and NLTK 3.\n",
            "(The original Python 2 version is still available at <a class=\"reference external\" href=\"https://www.nltk.org/book_1ed\">https://www.nltk.org/book_1ed</a>.)</p>\n",
            "<section id=\"some-simple-things-you-can-do-with-nltk\">\n",
            "<h2>Some simple things you can do with NLTK<a class=\"headerlink\" href=\"#some-simple-things-you-can-do-with-nltk\" title=\"Permalink to this headline\">¬∂</a></h2>\n",
            "<p>Tokenize and tag some text:</p>\n",
            "<div class=\"doctest highlight-default notranslate\"><div class=\"highlight\"><pre><span></span><span class=\"gp\">&gt;&gt;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsbElsgekjkh",
        "outputId": "2d67bb14-66f4-4aff-d4a0-7626f3749b19"
      },
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    [s.extract() for s in soup(['iframe', 'script'])]\n",
        "    stripped_text = soup.get_text()\n",
        "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text) # remove multiple breaklines\n",
        "    return stripped_text\n",
        "\n",
        "clean_content = strip_html_tags(content)\n",
        "print(clean_content)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "NLTK is a leading platform for building Python programs to work with human language data.\n",
            "It provides easy-to-use interfaces to over 50 corpora and lexical\n",
            "resources such as WordNet,\n",
            "along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,\n",
            "wrappers for industrial-strength NLP libraries,\n",
            "and an active discussion forum.\n",
            "Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,\n",
            "NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.\n",
            "NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.\n",
            "NLTK has been called ‚Äúa wonderful tool for teaching, and working in, computational linguistics using Python,‚Äù\n",
            "and ‚Äúan amazing library to play with natural language.‚Äù\n",
            "Natural Language Processing with Python provides a practical\n",
            "introduction to programming for language processing.\n",
            "Written by the creators of NLTK, it guides the reader through the fundamentals\n",
            "of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,\n",
            "and more.\n",
            "The online version of the book has been been updated for Python 3 and NLTK 3.\n",
            "(The original Python 2 version is still available at https://www.nltk.org/book_1ed.)\n",
            "Some simple things you can do with NLTK¬∂\n",
            "Tokenize and tag some text:\n",
            ">>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKDMFaVembXz"
      },
      "source": [
        "#### Removing accented characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx6A_65gl-1z",
        "outputId": "4b7eef13-3fd4-47b0-928a-ccd37ac49f88"
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "s = 'S√≥mƒõ √Åccƒõntƒõd tƒõxt'\n",
        "print(s)\n",
        "print(remove_accented_chars(s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S√≥mƒõ √Åccƒõntƒõd tƒõxt\n",
            "Some Accented text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2YU7rj3msed"
      },
      "source": [
        "#### Removing Special Characters, Numbers and Symbols\n",
        "\n",
        "Regex can be used to parse specific set of characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M-vx24Vmo5N",
        "outputId": "7b81d595-1ed4-44ac-a540-ffe89c774ad0"
      },
      "source": [
        "import re\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "s = \"Well this was fun! See you at 7:30, What do you think!!? #$@@9318@ üôÇüôÇüôÇ\"\n",
        "print(s)\n",
        "print(remove_special_characters(s))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Well this was fun! See you at 7:30, What do you think!!? #$@@9318@ üôÇüôÇüôÇ\n",
            "Well this was fun See you at 730 What do you think 9318 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHGaidfjnFgf"
      },
      "source": [
        "#### Expanding Contractions\n",
        "can't --> can not\n",
        "\n",
        "I'd --> I would"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h5UxUBWm6vI",
        "outputId": "d06bbb04-92eb-4c62-e653-9c1feff3ed71"
      },
      "source": [
        "!pip install contractions\n",
        "!pip install textsearch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.0.55-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 284 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 321 kB 32.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85448 sha256=30f3069eab7a3b593d5ac577fd7f138aee65dbc3f5960d8f54903fa886f46cec\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.0 contractions-0.0.55 pyahocorasick-1.4.2 textsearch-0.0.21\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.7/dist-packages (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch) (1.4.2)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch) (0.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "JkUj_GMdnhYg",
        "outputId": "7427bcce-5bda-4d36-c13e-90bc1b195aaf"
      },
      "source": [
        "import contractions\n",
        "\n",
        "s = \"Y'all can't expand contractions I'd think! You wouldn't be able to. How'd you do it?\"\n",
        "contractions.fix(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'you all cannot expand contractions I would think! You would not be able to. how did you do it?'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INq3p09eoEZl"
      },
      "source": [
        "#### Stemming\n",
        "If there is a different form of same word, stemming standardize it to just one word.\n",
        "\n",
        "Stemming cares only about syntax. It doesn't care about meaning. As a output we may get a word which doesn't exist in dictionary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS8aeP2boAIz",
        "outputId": "ba77c3dc-d68d-40f0-c148-aed34fe923cb"
      },
      "source": [
        "# using porter stemmer, other alternatives are snowball and lancaster stemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "print(ps.stem('jumping'), ps.stem('jumps'), ps.stem('jumped'))\n",
        "print(ps.stem('lying'))\n",
        "print(ps.stem('strange'))  # meaningless output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jump jump jump\n",
            "lie\n",
            "strang\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpdKldg6pqJj"
      },
      "source": [
        "#### Lemmatization\n",
        "\n",
        "Takes care of meaning as well by looking into dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rmsxkQvom_h",
        "outputId": "51040712-9f7d-4d4b-b09e-e9e81d17f2ce"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "# lemmatize nouns\n",
        "print(wnl.lemmatize('cars', 'n'))\n",
        "print(wnl.lemmatize('boxes', 'n'))\n",
        "\n",
        "# lemmatize verbs\n",
        "print(wnl.lemmatize('running', 'v'))\n",
        "print(wnl.lemmatize('ate', 'v'))\n",
        "\n",
        "# lemmatize adjectives\n",
        "print(wnl.lemmatize('saddest', 'a'))\n",
        "print(wnl.lemmatize('fancier', 'a'))\n",
        "\n",
        "# ineffective lemmatization\n",
        "print(wnl.lemmatize('ate', 'n'))\n",
        "print(wnl.lemmatize('fancier', 'v'))\n",
        "print(wnl.lemmatize('fancier'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "car\n",
            "box\n",
            "run\n",
            "eat\n",
            "sad\n",
            "fancy\n",
            "ate\n",
            "fancier\n",
            "fancier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcT5oNvxr5qa"
      },
      "source": [
        "To lemmatize a complete sentence we will have to idetify speech tag (noun, verb adjective) for each word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HyY-q7fLrNbg",
        "outputId": "07062a78-99bf-4a9e-a763-f0d6ade7a495"
      },
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "wnl = WordNetLemmatizer()\n",
        "\n",
        "def pos_tag_wordnet(tagged_tokens):\n",
        "    tag_map = {'j': wordnet.ADJ, 'v': wordnet.VERB, 'n': wordnet.NOUN, 'r': wordnet.ADV}\n",
        "    new_tagged_tokens = [(word, tag_map.get(tag[0].lower(), wordnet.NOUN))\n",
        "                            for word, tag in tagged_tokens]\n",
        "    return new_tagged_tokens\n",
        "def wordnet_lemmatize_text(text):\n",
        "    tagged_tokens = nltk.pos_tag(nltk.word_tokenize(text))\n",
        "    wordnet_tokens = pos_tag_wordnet(tagged_tokens)\n",
        "    lemmatized_text = ' '.join(wnl.lemmatize(word, tag) for word, tag in wordnet_tokens)\n",
        "    return lemmatized_text\n",
        "\n",
        "s = 'The brown foxes are quick and they are jumping over the sleeping lazy dogs!'\n",
        "wordnet_lemmatize_text(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The brown fox be quick and they be jump over the sleep lazy dog !'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTO3GxTvs1zn"
      },
      "source": [
        "#### Stopword removals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMxLBlFDsPo6",
        "outputId": "a1fff547-b5d5-4f01-e827-8cc99d486c0a"
      },
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "print(stop_words[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TjXTRsb3s8VK",
        "outputId": "f63e2506-1eb8-4574-f529-1a16a6b412f2"
      },
      "source": [
        "def remove_stopwords(text, is_lower_case=False, stopwords=None):\n",
        "    if not stopwords:\n",
        "        stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    \n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
        "    \n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n",
        "s = 'The brown foxes are quick and they are jumping over the sleeping lazy dogs!'\n",
        "remove_stopwords(s, is_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'brown foxes quick jumping sleeping lazy dogs !'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8qlPpDzv3S7"
      },
      "source": [
        "## Module 3 - Text Representation Models\n",
        "\n",
        "Machine learning models cannot understand unstructured text. Hence we need to convert text into some numeric representations which can be understood by machines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrFCENwrwlFr"
      },
      "source": [
        "### Traditional Text Representation Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "h_aUy-mLwD2u",
        "outputId": "4805a944-ae6d-4c6d-e8e9-6d47948ede1b"
      },
      "source": [
        "# Prepare a sample corpus\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.options.display.max_colwidth = 200\n",
        "\n",
        "corpus = ['The sky is blue and beautiful.',\n",
        "          'Love this blue and beautiful sky!',\n",
        "          'The quick brown fox jumps over the lazy dog.',\n",
        "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
        "          'I love green eggs, ham, sausages and bacon!',\n",
        "          'The brown fox is quick and the blue dog is lazy!',\n",
        "          'The sky is very blue and the sky is very beautiful today',\n",
        "          'The dog is lazy but the brown fox is quick!'    \n",
        "]\n",
        "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
        "\n",
        "corpus = np.array(corpus)\n",
        "corpus_df = pd.DataFrame({'Document': corpus, \n",
        "                          'Category': labels})\n",
        "corpus_df = corpus_df[['Document', 'Category']]\n",
        "corpus_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue and beautiful.</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this blue and beautiful sky!</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The dog is lazy but the brown fox is quick!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             Document Category\n",
              "0                                      The sky is blue and beautiful.  weather\n",
              "1                                   Love this blue and beautiful sky!  weather\n",
              "2                        The quick brown fox jumps over the lazy dog.  animals\n",
              "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
              "4                         I love green eggs, ham, sausages and bacon!     food\n",
              "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
              "6            The sky is very blue and the sky is very beautiful today  weather\n",
              "7                         The dog is lazy but the brown fox is quick!  animals"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KuaXubYyLPL",
        "outputId": "fc87d3a8-d770-4275-9a0e-5d34daa76853"
      },
      "source": [
        "# pre-processing of text to remove stop words\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def normalize_document(doc):\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
        "    doc = doc.lower()\n",
        "    doc = doc.strip()\n",
        "    # tokenize document\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    # filter stopwords out of document\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc\n",
        "\n",
        "normalize_corpus = np.vectorize(normalize_document)\n",
        "\n",
        "norm_corpus = normalize_corpus(corpus)\n",
        "norm_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sky blue beautiful', 'love blue beautiful sky',\n",
              "       'quick brown fox jumps lazy dog',\n",
              "       'kings breakfast sausages ham bacon eggs toast beans',\n",
              "       'love green eggs ham sausages bacon',\n",
              "       'brown fox quick blue dog lazy', 'sky blue sky beautiful today',\n",
              "       'dog lazy brown fox quick'], dtype='<U51')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLlNtZu1wptq"
      },
      "source": [
        "#### Bag of words\n",
        "\n",
        "Each document is represented by a vector of words. Each cell depicts the number of times each word occurs in that document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "op-O89ROxJB1",
        "outputId": "f8e1a394-a02b-40a5-85b5-5b0003ee7079"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(min_df=0., max_df=1.)\n",
        "cv_matrix = cv.fit_transform(norm_corpus)\n",
        "cv_matrix = cv_matrix.toarray()\n",
        "\n",
        "# get all unique words in the corpus\n",
        "vocab = cv.get_feature_names()\n",
        "# show document feature vectors\n",
        "pd.DataFrame(cv_matrix, columns=vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon</th>\n",
              "      <th>beans</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>breakfast</th>\n",
              "      <th>brown</th>\n",
              "      <th>dog</th>\n",
              "      <th>eggs</th>\n",
              "      <th>fox</th>\n",
              "      <th>green</th>\n",
              "      <th>ham</th>\n",
              "      <th>jumps</th>\n",
              "      <th>kings</th>\n",
              "      <th>lazy</th>\n",
              "      <th>love</th>\n",
              "      <th>quick</th>\n",
              "      <th>sausages</th>\n",
              "      <th>sky</th>\n",
              "      <th>toast</th>\n",
              "      <th>today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bacon  beans  beautiful  blue  breakfast  ...  quick  sausages  sky  toast  today\n",
              "0      0      0          1     1          0  ...      0         0    1      0      0\n",
              "1      0      0          1     1          0  ...      0         0    1      0      0\n",
              "2      0      0          0     0          0  ...      1         0    0      0      0\n",
              "3      1      1          0     0          1  ...      0         1    0      1      0\n",
              "4      1      0          0     0          0  ...      0         1    0      0      0\n",
              "5      0      0          0     1          0  ...      1         0    0      0      0\n",
              "6      0      0          1     1          0  ...      0         0    2      0      1\n",
              "7      0      0          0     0          0  ...      1         0    0      0      0\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu2nvrUdyk6j"
      },
      "source": [
        "#### Bag of N-Grams Model\n",
        "\n",
        "Similar to bag of words model. Instead of considering a single word we consider sequence of 2 or more words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "CGXaMnC5xlN_",
        "outputId": "e2da2e9b-2115-4296-f504-52181625787b"
      },
      "source": [
        "# you can set the n-gram range to 1,2 to get unigrams as well as bigrams\n",
        "bv = CountVectorizer(ngram_range=(2,2))\n",
        "bv_matrix = bv.fit_transform(norm_corpus)\n",
        "\n",
        "bv_matrix = bv_matrix.toarray()\n",
        "vocab = bv.get_feature_names()\n",
        "pd.DataFrame(bv_matrix, columns=vocab)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon eggs</th>\n",
              "      <th>beautiful sky</th>\n",
              "      <th>beautiful today</th>\n",
              "      <th>blue beautiful</th>\n",
              "      <th>blue dog</th>\n",
              "      <th>blue sky</th>\n",
              "      <th>breakfast sausages</th>\n",
              "      <th>brown fox</th>\n",
              "      <th>dog lazy</th>\n",
              "      <th>eggs ham</th>\n",
              "      <th>eggs toast</th>\n",
              "      <th>fox jumps</th>\n",
              "      <th>fox quick</th>\n",
              "      <th>green eggs</th>\n",
              "      <th>ham bacon</th>\n",
              "      <th>ham sausages</th>\n",
              "      <th>jumps lazy</th>\n",
              "      <th>kings breakfast</th>\n",
              "      <th>lazy brown</th>\n",
              "      <th>lazy dog</th>\n",
              "      <th>love blue</th>\n",
              "      <th>love green</th>\n",
              "      <th>quick blue</th>\n",
              "      <th>quick brown</th>\n",
              "      <th>sausages bacon</th>\n",
              "      <th>sausages ham</th>\n",
              "      <th>sky beautiful</th>\n",
              "      <th>sky blue</th>\n",
              "      <th>toast beans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bacon eggs  beautiful sky  ...  sky blue  toast beans\n",
              "0           0              0  ...         1            0\n",
              "1           0              1  ...         0            0\n",
              "2           0              0  ...         0            0\n",
              "3           1              0  ...         0            1\n",
              "4           0              0  ...         0            0\n",
              "5           0              0  ...         0            0\n",
              "6           0              0  ...         1            0\n",
              "7           0              0  ...         0            0\n",
              "\n",
              "[8 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpNS_yDNzLUv"
      },
      "source": [
        "#### TF-IDF Model\n",
        "\n",
        "TF-IDF stands for Term Frequency-Inverse Document Frequency. It normalize counts of words using the inverse document frequency to downplay effect of frequently occuring words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "uQM6BdLyyshl",
        "outputId": "b4aea852-5ddd-4c23-feee-f4067efe7ab1"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
        "tv_matrix = tv.fit_transform(norm_corpus)\n",
        "tv_matrix = tv_matrix.toarray()\n",
        "\n",
        "vocab = tv.get_feature_names()\n",
        "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bacon</th>\n",
              "      <th>beans</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>breakfast</th>\n",
              "      <th>brown</th>\n",
              "      <th>dog</th>\n",
              "      <th>eggs</th>\n",
              "      <th>fox</th>\n",
              "      <th>green</th>\n",
              "      <th>ham</th>\n",
              "      <th>jumps</th>\n",
              "      <th>kings</th>\n",
              "      <th>lazy</th>\n",
              "      <th>love</th>\n",
              "      <th>quick</th>\n",
              "      <th>sausages</th>\n",
              "      <th>sky</th>\n",
              "      <th>toast</th>\n",
              "      <th>today</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bacon  beans  beautiful  blue  ...  sausages   sky  toast  today\n",
              "0   0.00   0.00       0.60  0.53  ...      0.00  0.60   0.00    0.0\n",
              "1   0.00   0.00       0.49  0.43  ...      0.00  0.49   0.00    0.0\n",
              "2   0.00   0.00       0.00  0.00  ...      0.00  0.00   0.00    0.0\n",
              "3   0.32   0.38       0.00  0.00  ...      0.32  0.00   0.38    0.0\n",
              "4   0.39   0.00       0.00  0.00  ...      0.39  0.00   0.00    0.0\n",
              "5   0.00   0.00       0.00  0.37  ...      0.00  0.00   0.00    0.0\n",
              "6   0.00   0.00       0.36  0.32  ...      0.00  0.72   0.00    0.5\n",
              "7   0.00   0.00       0.00  0.00  ...      0.00  0.00   0.00    0.0\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjK0Ppnlz0qz"
      },
      "source": [
        "#### Document Similarity\n",
        "\n",
        "Document similarity is the process of using a distance or similarity based metric that can be used to identify how similar a text document is with any other document(s) based on features extracted from the documents like bag of words or tf-idf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "aUx9hvHlzr_n",
        "outputId": "37aa1695-2012-40a2-c01c-45a6c9f92ed3"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_matrix = cosine_similarity(tv_matrix)\n",
        "similarity_df = pd.DataFrame(similarity_matrix)\n",
        "similarity_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.820599</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.192353</td>\n",
              "      <td>0.817246</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.820599</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.225489</td>\n",
              "      <td>0.157845</td>\n",
              "      <td>0.670631</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.791821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.850516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.506866</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.225489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.506866</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.192353</td>\n",
              "      <td>0.157845</td>\n",
              "      <td>0.791821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.115488</td>\n",
              "      <td>0.930989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.817246</td>\n",
              "      <td>0.670631</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.115488</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.850516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.930989</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...         5         6         7\n",
              "0  1.000000  0.820599  0.000000  ...  0.192353  0.817246  0.000000\n",
              "1  0.820599  1.000000  0.000000  ...  0.157845  0.670631  0.000000\n",
              "2  0.000000  0.000000  1.000000  ...  0.791821  0.000000  0.850516\n",
              "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "4  0.000000  0.225489  0.000000  ...  0.000000  0.000000  0.000000\n",
              "5  0.192353  0.157845  0.791821  ...  1.000000  0.115488  0.930989\n",
              "6  0.817246  0.670631  0.000000  ...  0.115488  1.000000  0.000000\n",
              "7  0.000000  0.000000  0.850516  ...  0.930989  0.000000  1.000000\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vUGtypqEz-rs",
        "outputId": "7675df5f-4485-404c-d1ef-17f86d1dcced"
      },
      "source": [
        "# Apply ML on text representation models\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "km = KMeans(n_clusters=3, random_state=0)\n",
        "km.fit_transform(similarity_matrix)\n",
        "cluster_labels = km.labels_\n",
        "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
        "pd.concat([corpus_df, cluster_labels], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Category</th>\n",
              "      <th>ClusterLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue and beautiful.</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this blue and beautiful sky!</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
              "      <td>food</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
              "      <td>food</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
              "      <td>weather</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The dog is lazy but the brown fox is quick!</td>\n",
              "      <td>animals</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                             Document  ... ClusterLabel\n",
              "0                                      The sky is blue and beautiful.  ...            2\n",
              "1                                   Love this blue and beautiful sky!  ...            2\n",
              "2                        The quick brown fox jumps over the lazy dog.  ...            1\n",
              "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans  ...            0\n",
              "4                         I love green eggs, ham, sausages and bacon!  ...            0\n",
              "5                    The brown fox is quick and the blue dog is lazy!  ...            1\n",
              "6            The sky is very blue and the sky is very beautiful today  ...            2\n",
              "7                         The dog is lazy but the brown fox is quick!  ...            1\n",
              "\n",
              "[8 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYjo0jw50JSu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8ecuryK0b07"
      },
      "source": [
        "### Word Embedding Models\n",
        "\n",
        "1. Word2Vec\n",
        "2. GloVe\n",
        "3. FastText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUBAwMTJ2QV5"
      },
      "source": [
        "## Module 4 - Downstream ML Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE1Q0JZb2VhS"
      },
      "source": [
        "### Movie Recommender System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trH5SDkM0kB5",
        "outputId": "39a8276e-acc9-4da9-c8db-aa0ae20e16f6"
      },
      "source": [
        "# Install Dependecies\n",
        "!pip install textsearch\n",
        "!pip install contractions\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.7/dist-packages (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch) (1.4.2)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch) (0.3.0)\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.55)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpM7v3U62v_Z",
        "outputId": "568cd3fb-0ed4-4a10-ae5a-dbed5abf31a7"
      },
      "source": [
        "# Load and view data\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2010%20-%20Project%208%20-%20Movie%20Recommendations%20with%20Document%20Similarity/tmdb_5000_movies.csv.gz', compression='gzip')\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4803 entries, 0 to 4802\n",
            "Data columns (total 20 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   budget                4803 non-null   int64  \n",
            " 1   genres                4803 non-null   object \n",
            " 2   homepage              1712 non-null   object \n",
            " 3   id                    4803 non-null   int64  \n",
            " 4   keywords              4803 non-null   object \n",
            " 5   original_language     4803 non-null   object \n",
            " 6   original_title        4803 non-null   object \n",
            " 7   overview              4800 non-null   object \n",
            " 8   popularity            4803 non-null   float64\n",
            " 9   production_companies  4803 non-null   object \n",
            " 10  production_countries  4803 non-null   object \n",
            " 11  release_date          4802 non-null   object \n",
            " 12  revenue               4803 non-null   int64  \n",
            " 13  runtime               4801 non-null   float64\n",
            " 14  spoken_languages      4803 non-null   object \n",
            " 15  status                4803 non-null   object \n",
            " 16  tagline               3959 non-null   object \n",
            " 17  title                 4803 non-null   object \n",
            " 18  vote_average          4803 non-null   float64\n",
            " 19  vote_count            4803 non-null   int64  \n",
            "dtypes: float64(3), int64(4), object(13)\n",
            "memory usage: 750.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sfGmn-1Z21Vw",
        "outputId": "bbca8f17-ea09-42de-b67b-3cd158af4a15"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>budget</th>\n",
              "      <th>genres</th>\n",
              "      <th>homepage</th>\n",
              "      <th>id</th>\n",
              "      <th>keywords</th>\n",
              "      <th>original_language</th>\n",
              "      <th>original_title</th>\n",
              "      <th>overview</th>\n",
              "      <th>popularity</th>\n",
              "      <th>production_companies</th>\n",
              "      <th>production_countries</th>\n",
              "      <th>release_date</th>\n",
              "      <th>revenue</th>\n",
              "      <th>runtime</th>\n",
              "      <th>spoken_languages</th>\n",
              "      <th>status</th>\n",
              "      <th>tagline</th>\n",
              "      <th>title</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>vote_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>237000000</td>\n",
              "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]</td>\n",
              "      <td>http://www.avatarmovie.com/</td>\n",
              "      <td>19995</td>\n",
              "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\": 2964, \"name\": \"future\"}, {\"id\": 3386, \"name\": \"space war\"}, {\"id\": 3388, \"name\": \"space colony\"}, {\"id\": 3679, \"name\": \"society\"}, {\"id\": 3801, \"name...</td>\n",
              "      <td>en</td>\n",
              "      <td>Avatar</td>\n",
              "      <td>In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization.</td>\n",
              "      <td>150.437577</td>\n",
              "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289}, {\"name\": \"Twentieth Century Fox Film Corporation\", \"id\": 306}, {\"name\": \"Dune Entertainment\", \"id\": 444}, {\"name\": \"Lightstorm Entertainment\", \"id\"...</td>\n",
              "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States of America\"}, {\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"}]</td>\n",
              "      <td>2009-12-10</td>\n",
              "      <td>2787965087</td>\n",
              "      <td>162.0</td>\n",
              "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>Enter the World of Pandora.</td>\n",
              "      <td>Avatar</td>\n",
              "      <td>7.2</td>\n",
              "      <td>11800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>300000000</td>\n",
              "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 28, \"name\": \"Action\"}]</td>\n",
              "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
              "      <td>285</td>\n",
              "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"name\": \"drug abuse\"}, {\"id\": 911, \"name\": \"exotic island\"}, {\"id\": 1319, \"name\": \"east india trading company\"}, {\"id\": 2038, \"name\": \"love of one's life...</td>\n",
              "      <td>en</td>\n",
              "      <td>Pirates of the Caribbean: At World's End</td>\n",
              "      <td>Captain Barbossa, long believed to be dead, has come back to life and is headed to the edge of the Earth with Will Turner and Elizabeth Swann. But nothing is quite as it seems.</td>\n",
              "      <td>139.082615</td>\n",
              "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"name\": \"Jerry Bruckheimer Films\", \"id\": 130}, {\"name\": \"Second Mate Productions\", \"id\": 19936}]</td>\n",
              "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States of America\"}]</td>\n",
              "      <td>2007-05-19</td>\n",
              "      <td>961000000</td>\n",
              "      <td>169.0</td>\n",
              "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>At the end of the world, the adventure begins.</td>\n",
              "      <td>Pirates of the Caribbean: At World's End</td>\n",
              "      <td>6.9</td>\n",
              "      <td>4500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>245000000</td>\n",
              "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 80, \"name\": \"Crime\"}]</td>\n",
              "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
              "      <td>206647</td>\n",
              "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name\": \"based on novel\"}, {\"id\": 4289, \"name\": \"secret agent\"}, {\"id\": 9663, \"name\": \"sequel\"}, {\"id\": 14555, \"name\": \"mi6\"}, {\"id\": 156095, \"name\": \"brit...</td>\n",
              "      <td>en</td>\n",
              "      <td>Spectre</td>\n",
              "      <td>A cryptic message from Bond‚Äôs past sends him on a trail to uncover a sinister organization. While M battles political forces to keep the secret service alive, Bond peels back the layers of deceit ...</td>\n",
              "      <td>107.376788</td>\n",
              "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"name\": \"Danjaq\", \"id\": 10761}, {\"name\": \"B24\", \"id\": 69434}]</td>\n",
              "      <td>[{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"}, {\"iso_3166_1\": \"US\", \"name\": \"United States of America\"}]</td>\n",
              "      <td>2015-10-26</td>\n",
              "      <td>880674609</td>\n",
              "      <td>148.0</td>\n",
              "      <td>[{\"iso_639_1\": \"fr\", \"name\": \"Fran\\u00e7ais\"}, {\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso_639_1\": \"es\", \"name\": \"Espa\\u00f1ol\"}, {\"iso_639_1\": \"it\", \"name\": \"Italiano\"}, {\"iso_639_1\": \"de\", \"na...</td>\n",
              "      <td>Released</td>\n",
              "      <td>A Plan No One Escapes</td>\n",
              "      <td>Spectre</td>\n",
              "      <td>6.3</td>\n",
              "      <td>4466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>250000000</td>\n",
              "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"name\": \"Crime\"}, {\"id\": 18, \"name\": \"Drama\"}, {\"id\": 53, \"name\": \"Thriller\"}]</td>\n",
              "      <td>http://www.thedarkknightrises.com/</td>\n",
              "      <td>49026</td>\n",
              "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853, \"name\": \"crime fighter\"}, {\"id\": 949, \"name\": \"terrorist\"}, {\"id\": 1308, \"name\": \"secret identity\"}, {\"id\": 1437, \"name\": \"burglar\"}, {\"id\": 3051, \"n...</td>\n",
              "      <td>en</td>\n",
              "      <td>The Dark Knight Rises</td>\n",
              "      <td>Following the death of District Attorney Harvey Dent, Batman assumes responsibility for Dent's crimes to protect the late attorney's reputation and is subsequently hunted by the Gotham City Police...</td>\n",
              "      <td>112.312950</td>\n",
              "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"name\": \"Warner Bros.\", \"id\": 6194}, {\"name\": \"DC Entertainment\", \"id\": 9993}, {\"name\": \"Syncopy\", \"id\": 9996}]</td>\n",
              "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States of America\"}]</td>\n",
              "      <td>2012-07-16</td>\n",
              "      <td>1084939099</td>\n",
              "      <td>165.0</td>\n",
              "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>The Legend Ends</td>\n",
              "      <td>The Dark Knight Rises</td>\n",
              "      <td>7.6</td>\n",
              "      <td>9106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>260000000</td>\n",
              "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]</td>\n",
              "      <td>http://movies.disney.com/john-carter</td>\n",
              "      <td>49529</td>\n",
              "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\": 839, \"name\": \"mars\"}, {\"id\": 1456, \"name\": \"medallion\"}, {\"id\": 3801, \"name\": \"space travel\"}, {\"id\": 7376, \"name\": \"princess\"}, {\"id\": 9951, \"name\":...</td>\n",
              "      <td>en</td>\n",
              "      <td>John Carter</td>\n",
              "      <td>John Carter is a war-weary, former military captain who's inexplicably transported to the mysterious and exotic planet of Barsoom (Mars) and reluctantly becomes embroiled in an epic conflict. It's...</td>\n",
              "      <td>43.926995</td>\n",
              "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
              "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States of America\"}]</td>\n",
              "      <td>2012-03-07</td>\n",
              "      <td>284139100</td>\n",
              "      <td>132.0</td>\n",
              "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>Lost in our world, found in another.</td>\n",
              "      <td>John Carter</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2124</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      budget  ... vote_count\n",
              "0  237000000  ...      11800\n",
              "1  300000000  ...       4500\n",
              "2  245000000  ...       4466\n",
              "3  250000000  ...       9106\n",
              "4  260000000  ...       2124\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "WuRjYkbe25ix",
        "outputId": "1e0fc293-69bf-4ef9-f79b-a1fa511bbfdb"
      },
      "source": [
        "# extract useful features from dataset\n",
        "df = df[['title', 'tagline', 'overview', 'popularity']]\n",
        "df.tagline.fillna('', inplace=True)\n",
        "df['description'] = df['tagline'].map(str) + ' ' + df['overview']\n",
        "df.dropna(inplace=True)\n",
        "df = df.sort_values(by=['popularity'], ascending=False)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  downcast=downcast,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>tagline</th>\n",
              "      <th>overview</th>\n",
              "      <th>popularity</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>Minions</td>\n",
              "      <td>Before Gru, they had a history of bad bosses</td>\n",
              "      <td>Minions Stuart, Kevin and Bob are recruited by Scarlet Overkill, a super-villain who, alongside her inventor husband Herb, hatches a plot to take over the world.</td>\n",
              "      <td>875.581305</td>\n",
              "      <td>Before Gru, they had a history of bad bosses Minions Stuart, Kevin and Bob are recruited by Scarlet Overkill, a super-villain who, alongside her inventor husband Herb, hatches a plot to take over ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Interstellar</td>\n",
              "      <td>Mankind was born on Earth. It was never meant to die here.</td>\n",
              "      <td>Interstellar chronicles the adventures of a group of explorers who make use of a newly discovered wormhole to surpass the limitations on human space travel and conquer the vast distances involved ...</td>\n",
              "      <td>724.247784</td>\n",
              "      <td>Mankind was born on Earth. It was never meant to die here. Interstellar chronicles the adventures of a group of explorers who make use of a newly discovered wormhole to surpass the limitations on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>Deadpool</td>\n",
              "      <td>Witness the beginning of a happy ending</td>\n",
              "      <td>Deadpool tells the origin story of former Special Forces operative turned mercenary Wade Wilson, who after being subjected to a rogue experiment that leaves him with accelerated healing powers, ad...</td>\n",
              "      <td>514.569956</td>\n",
              "      <td>Witness the beginning of a happy ending Deadpool tells the origin story of former Special Forces operative turned mercenary Wade Wilson, who after being subjected to a rogue experiment that leaves...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>Guardians of the Galaxy</td>\n",
              "      <td>All heroes start somewhere.</td>\n",
              "      <td>Light years from Earth, 26 years after being abducted, Peter Quill finds himself the prime target of a manhunt after discovering an orb wanted by Ronan the Accuser.</td>\n",
              "      <td>481.098624</td>\n",
              "      <td>All heroes start somewhere. Light years from Earth, 26 years after being abducted, Peter Quill finds himself the prime target of a manhunt after discovering an orb wanted by Ronan the Accuser.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>Mad Max: Fury Road</td>\n",
              "      <td>What a Lovely Day.</td>\n",
              "      <td>An apocalyptic story set in the furthest reaches of our planet, in a stark desert landscape where humanity is broken, and most everyone is crazed fighting for the necessities of life. Within this ...</td>\n",
              "      <td>434.278564</td>\n",
              "      <td>What a Lovely Day. An apocalyptic story set in the furthest reaches of our planet, in a stark desert landscape where humanity is broken, and most everyone is crazed fighting for the necessities of...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       title  ...                                                                                                                                                                                              description\n",
              "546                  Minions  ...  Before Gru, they had a history of bad bosses Minions Stuart, Kevin and Bob are recruited by Scarlet Overkill, a super-villain who, alongside her inventor husband Herb, hatches a plot to take over ...\n",
              "95              Interstellar  ...  Mankind was born on Earth. It was never meant to die here. Interstellar chronicles the adventures of a group of explorers who make use of a newly discovered wormhole to surpass the limitations on ...\n",
              "788                 Deadpool  ...  Witness the beginning of a happy ending Deadpool tells the origin story of former Special Forces operative turned mercenary Wade Wilson, who after being subjected to a rogue experiment that leaves...\n",
              "94   Guardians of the Galaxy  ...         All heroes start somewhere. Light years from Earth, 26 years after being abducted, Peter Quill finds himself the prime target of a manhunt after discovering an orb wanted by Ronan the Accuser.\n",
              "127       Mad Max: Fury Road  ...  What a Lovely Day. An apocalyptic story set in the furthest reaches of our planet, in a stark desert landscape where humanity is broken, and most everyone is crazed fighting for the necessities of...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfdgWmA73Me5",
        "outputId": "020a5c3b-f76b-4aec-ccb9-0aeec2eb6fde"
      },
      "source": [
        "# Text pre-processing\n",
        "import nltk\n",
        "import re\n",
        "import numpy as np\n",
        "import contractions\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def normalize_document(doc):\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
        "    doc = doc.lower()\n",
        "    doc = doc.strip()\n",
        "    doc = contractions.fix(doc)\n",
        "    # tokenize document\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    #filter stopwords out of document\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc\n",
        "\n",
        "normalize_corpus = np.vectorize(normalize_document)\n",
        "\n",
        "norm_corpus = normalize_corpus(list(df['description']))\n",
        "norm_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['gru history bad bosses minions stuart kevin bob recruited scarlet overkill supervillain alongside inventor husband herb hatches plot take world',\n",
              "       'mankind born earth never meant die interstellar chronicles adventures group explorers make use newly discovered wormhole surpass limitations human space travel conquer vast distances involved interstellar voyage',\n",
              "       'witness beginning happy ending deadpool tells origin story former special forces operative turned mercenary wade wilson subjected rogue experiment leaves accelerated healing powers adopts alter ego deadpool armed new abilities dark twisted sense humor deadpool hunts man nearly destroyed life',\n",
              "       ...,\n",
              "       'one way 100 fools stand way hitchhiker named martel gordone gets fight two bikers prostitute one bikers killed gordone arrested sent prison joins prisons boxing team effort secure early parole establish dominance prisons toughest gang',\n",
              "       'dare go man affair married woman dropped wrong street going back hotel takes refuge rain old man invites turns mortician tells stories people wound establishment course four stories',\n",
              "       '1971 post civil rights san francisco seemed like perfect place black korean war veteran family realize dream economic independence chance boss charlie walker would soon find naive city full impostors naysayers refused take answer catastrophic disaster opened door never open black man story happened stepped door feet'],\n",
              "      dtype='<U797')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QUsE-6-3jNE",
        "outputId": "ad4c6f48-1447-42fc-ebbe-6137ebde7baa"
      },
      "source": [
        "# Extract TF-IDF feature\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
        "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
        "tfidf_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4800, 20471)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "3e9APwec3rlY",
        "outputId": "c68ebf7b-257a-43e5-b145-4b837cc4bf45"
      },
      "source": [
        "# Compute pair-wise cosine similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "doc_sim = cosine_similarity(tfidf_matrix)\n",
        "doc_sim_df = pd.DataFrame(doc_sim)\n",
        "doc_sim_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>4760</th>\n",
              "      <th>4761</th>\n",
              "      <th>4762</th>\n",
              "      <th>4763</th>\n",
              "      <th>4764</th>\n",
              "      <th>4765</th>\n",
              "      <th>4766</th>\n",
              "      <th>4767</th>\n",
              "      <th>4768</th>\n",
              "      <th>4769</th>\n",
              "      <th>4770</th>\n",
              "      <th>4771</th>\n",
              "      <th>4772</th>\n",
              "      <th>4773</th>\n",
              "      <th>4774</th>\n",
              "      <th>4775</th>\n",
              "      <th>4776</th>\n",
              "      <th>4777</th>\n",
              "      <th>4778</th>\n",
              "      <th>4779</th>\n",
              "      <th>4780</th>\n",
              "      <th>4781</th>\n",
              "      <th>4782</th>\n",
              "      <th>4783</th>\n",
              "      <th>4784</th>\n",
              "      <th>4785</th>\n",
              "      <th>4786</th>\n",
              "      <th>4787</th>\n",
              "      <th>4788</th>\n",
              "      <th>4789</th>\n",
              "      <th>4790</th>\n",
              "      <th>4791</th>\n",
              "      <th>4792</th>\n",
              "      <th>4793</th>\n",
              "      <th>4794</th>\n",
              "      <th>4795</th>\n",
              "      <th>4796</th>\n",
              "      <th>4797</th>\n",
              "      <th>4798</th>\n",
              "      <th>4799</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006071</td>\n",
              "      <td>0.008067</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025531</td>\n",
              "      <td>0.008554</td>\n",
              "      <td>0.018111</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007439</td>\n",
              "      <td>0.010454</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008190</td>\n",
              "      <td>0.008365</td>\n",
              "      <td>0.010035</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050976</td>\n",
              "      <td>0.006502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010728</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006908</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.167573</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009191</td>\n",
              "      <td>0.053475</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009711</td>\n",
              "      <td>0.006508</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.02841</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008870</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.033246</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.034092</td>\n",
              "      <td>0.018758</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037930</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017839</td>\n",
              "      <td>0.007968</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012501</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014840</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012814</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016898</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008885</td>\n",
              "      <td>0.009432</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014947</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022738</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019783</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011407</td>\n",
              "      <td>0.011409</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.021596</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017564</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019152</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017178</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024326</td>\n",
              "      <td>0.005471</td>\n",
              "      <td>0.018038</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005099</td>\n",
              "      <td>0.004985</td>\n",
              "      <td>0.004705</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004843</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017026</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003672</td>\n",
              "      <td>0.003984</td>\n",
              "      <td>0.030998</td>\n",
              "      <td>0.006959</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006117</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019548</td>\n",
              "      <td>0.020365</td>\n",
              "      <td>0.009213</td>\n",
              "      <td>0.028467</td>\n",
              "      <td>0.010515</td>\n",
              "      <td>0.004198</td>\n",
              "      <td>0.006311</td>\n",
              "      <td>0.015154</td>\n",
              "      <td>0.012698</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020597</td>\n",
              "      <td>0.004723</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016673</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006972</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010574</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008222</td>\n",
              "      <td>0.008604</td>\n",
              "      <td>0.012782</td>\n",
              "      <td>0.015353</td>\n",
              "      <td>0.006259</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010555</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006903</td>\n",
              "      <td>0.005024</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012893</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025975</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027126</td>\n",
              "      <td>0.009340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017839</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022414</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037207</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027958</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012232</td>\n",
              "      <td>0.017893</td>\n",
              "      <td>0.043639</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023127</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009324</td>\n",
              "      <td>0.022995</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044476</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014029</td>\n",
              "      <td>0.030562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.018486</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.060846</td>\n",
              "      <td>0.025039</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036237</td>\n",
              "      <td>0.030516</td>\n",
              "      <td>0.022605</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.006071</td>\n",
              "      <td>0.007968</td>\n",
              "      <td>0.017178</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.004673</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.064581</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036616</td>\n",
              "      <td>0.023883</td>\n",
              "      <td>0.014423</td>\n",
              "      <td>0.012317</td>\n",
              "      <td>0.019837</td>\n",
              "      <td>0.008171</td>\n",
              "      <td>0.004308</td>\n",
              "      <td>0.025463</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008909</td>\n",
              "      <td>0.023739</td>\n",
              "      <td>0.011343</td>\n",
              "      <td>0.003009</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026932</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019560</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028525</td>\n",
              "      <td>0.016020</td>\n",
              "      <td>0.011313</td>\n",
              "      <td>0.016914</td>\n",
              "      <td>0.022977</td>\n",
              "      <td>0.054149</td>\n",
              "      <td>0.013769</td>\n",
              "      <td>0.027401</td>\n",
              "      <td>0.005417</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005089</td>\n",
              "      <td>0.015099</td>\n",
              "      <td>0.030763</td>\n",
              "      <td>0.013665</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.012626</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027022</td>\n",
              "      <td>0.012027</td>\n",
              "      <td>0.005714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017233</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022330</td>\n",
              "      <td>0.007052</td>\n",
              "      <td>0.038019</td>\n",
              "      <td>0.011785</td>\n",
              "      <td>0.018614</td>\n",
              "      <td>0.021471</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003768</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008651</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012751</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022064</td>\n",
              "      <td>0.019662</td>\n",
              "      <td>0.036561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076033</td>\n",
              "      <td>0.004516</td>\n",
              "      <td>0.043475</td>\n",
              "      <td>0.011465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 4800 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0         1         2     ...      4797      4798      4799\n",
              "0  1.000000  0.000000  0.000000  ...  0.000000  0.000000  0.009646\n",
              "1  0.000000  1.000000  0.000000  ...  0.000000  0.000000  0.007963\n",
              "2  0.000000  0.000000  1.000000  ...  0.000000  0.027126  0.009340\n",
              "3  0.000000  0.017839  0.000000  ...  0.000000  0.000000  0.000000\n",
              "4  0.006071  0.007968  0.017178  ...  0.004516  0.043475  0.011465\n",
              "\n",
              "[5 rows x 4800 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsZZWBXy42Cd"
      },
      "source": [
        "# get movie titles\n",
        "movies_list = df['title'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfJXnF-n3zDa"
      },
      "source": [
        "def movie_recommender(movie_title, movies=movies_list, doc_sims=doc_sim_df):\n",
        "    # find movie id\n",
        "    movie_idx = np.where(movies == movie_title)[0][0]\n",
        "    # get movie similarities\n",
        "    movie_similarities = doc_sims.iloc[movie_idx].values\n",
        "    # get top 5 similar movie IDs\n",
        "    similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
        "    # get top 5 movies\n",
        "    similar_movies = movies[similar_movie_idxs]\n",
        "    # return the top 5 movies\n",
        "    return similar_movies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaYyWjJ54hjL",
        "outputId": "fb2367cd-72c1-4723-f352-2cb948a9e865"
      },
      "source": [
        "popular_movies = ['Minions', 'Interstellar', 'Deadpool', 'Jurassic World', 'Pirates of the Caribbean: The Curse of the Black Pearl',\n",
        "              'Dawn of the Planet of the Apes', 'Captain America: Civil War', 'Batman v Superman: Dawn of Justice', \n",
        "              'The Shawshank Redemption', 'Harry Potter and the Chamber of Secrets', 'Star Wars']\n",
        "\n",
        "for movie in popular_movies:\n",
        "    print('Movie:', movie)\n",
        "    print('Top 5 recommended Movies:', movie_recommender(movie_title=movie, movies=movies_list, doc_sims=doc_sim_df))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movie: Minions\n",
            "Top 5 recommended Movies: ['Despicable Me 2' 'Despicable Me'\n",
            " 'Teenage Mutant Ninja Turtles: Out of the Shadows' 'Superman'\n",
            " 'Rise of the Guardians']\n",
            "\n",
            "Movie: Interstellar\n",
            "Top 5 recommended Movies: ['Gattaca' 'Space Pirate Captain Harlock' 'Space Cowboys'\n",
            " 'Starship Troopers' 'Final Destination 2']\n",
            "\n",
            "Movie: Deadpool\n",
            "Top 5 recommended Movies: ['Silent Trigger' 'Underworld: Evolution' 'Bronson' 'Shaft' 'Don Jon']\n",
            "\n",
            "Movie: Jurassic World\n",
            "Top 5 recommended Movies: ['Jurassic Park' 'The Lost World: Jurassic Park'\n",
            " \"National Lampoon's Vacation\" 'The Nut Job' 'Vacation']\n",
            "\n",
            "Movie: Pirates of the Caribbean: The Curse of the Black Pearl\n",
            "Top 5 recommended Movies: [\"Pirates of the Caribbean: Dead Man's Chest\"\n",
            " 'Pirates of the Caribbean: On Stranger Tides' 'The Pirate'\n",
            " 'The Pirates! In an Adventure with Scientists!' 'Joyful Noise']\n",
            "\n",
            "Movie: Dawn of the Planet of the Apes\n",
            "Top 5 recommended Movies: ['Battle for the Planet of the Apes' 'Groove' 'The Other End of the Line'\n",
            " 'Chicago Overcoat' 'Definitely, Maybe']\n",
            "\n",
            "Movie: Captain America: Civil War\n",
            "Top 5 recommended Movies: ['Captain America: The Winter Soldier' 'This Means War'\n",
            " 'Avengers: Age of Ultron' 'Iron Man 2' 'Escape from Tomorrow']\n",
            "\n",
            "Movie: Batman v Superman: Dawn of Justice\n",
            "Top 5 recommended Movies: ['Batman Returns' 'The Punisher' 'Defendor'\n",
            " 'Batman: The Dark Knight Returns, Part 2' 'Nowhere to Run']\n",
            "\n",
            "Movie: The Shawshank Redemption\n",
            "Top 5 recommended Movies: ['Civil Brand' 'Les Mis√©rables' 'The Chorus' 'Prison' 'Fortress']\n",
            "\n",
            "Movie: Harry Potter and the Chamber of Secrets\n",
            "Top 5 recommended Movies: ['Harry Potter and the Prisoner of Azkaban'\n",
            " 'Harry Potter and the Goblet of Fire'\n",
            " 'Harry Potter and the Order of the Phoenix'\n",
            " 'Harry Potter and the Half-Blood Prince'\n",
            " \"Harry Potter and the Philosopher's Stone\"]\n",
            "\n",
            "Movie: Star Wars\n",
            "Top 5 recommended Movies: ['The Empire Strikes Back' 'Return of the Jedi' 'Shrek the Third'\n",
            " 'The Ice Pirates' 'The Tale of Despereaux']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8WLPE5c7nda"
      },
      "source": [
        "### Product Classification based on reviews "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6gyJ9u9A48qh",
        "outputId": "776d6c78-66d1-40f5-92fc-40ed71ff74da"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Data link - https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dipanjanS/feature_engineering_session_dhs18/master/ecommerce_product_ratings_prediction/Womens%20Clothing%20E-Commerce%20Reviews.csv', keep_default_na=False)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td></td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td></td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i co...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Clothing ID  Age  ...   Division Name Department Name  Class Name\n",
              "0           0          767   33  ...       Initmates        Intimate   Intimates\n",
              "1           1         1080   34  ...         General         Dresses     Dresses\n",
              "2           2         1077   60  ...         General         Dresses     Dresses\n",
              "3           3         1049   50  ...  General Petite         Bottoms       Pants\n",
              "4           4          847   47  ...         General            Tops     Blouses\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "HCYMlhPj7zNA",
        "outputId": "0f2eaf8d-f47b-457d-f827-330eb53ba298"
      },
      "source": [
        "# Basic pre-processing\n",
        "\n",
        "# merge review and title\n",
        "df['Review'] = (df['Title'].map(str) +' '+ df['Review Text']).apply(lambda row: row.strip())\n",
        "\n",
        "# convert rating to binary format\n",
        "df['Rating'] = [1 if rating > 3 else 0 for rating in df['Rating']]\n",
        "\n",
        "df = df[['Review', 'Rating']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Some major design flaws I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My favorite buy! I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Flattering shirt This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                    Review  Rating\n",
              "0                                                                                                                                                    Absolutely wonderful - silky and sexy and comfortable       1\n",
              "1  Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length...       1\n",
              "2  Some major design flaws I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so...       0\n",
              "3                                                            My favorite buy! I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!       1\n",
              "4  Flattering shirt This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love ...       1"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HGpy4gv8Gq6",
        "outputId": "874f485d-2f1e-46e1-eadd-486119955888"
      },
      "source": [
        "# remove all records with no review text\n",
        "df = df[df['Review'] != '']\n",
        "df['Rating'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    17449\n",
              "0     5193\n",
              "Name: Rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9zaa37E8UoE",
        "outputId": "2155d2c5-2f60-426b-c347-96c17905a463"
      },
      "source": [
        "# Build train and test datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['Review']], df['Rating'], random_state=42)\n",
        "X_train.shape, X_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16981, 1), (5661, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbFBUfwg8tDG"
      },
      "source": [
        "#### Basic NLP count based features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "46CKRwSa8egm",
        "outputId": "583b7e70-85b6-4570-d9af-7e0ad81bed16"
      },
      "source": [
        "import string\n",
        "\n",
        "X_train['char_count'] = X_train['Review'].apply(len)\n",
        "X_train['word_count'] = X_train['Review'].apply(lambda x: len(x.split()))\n",
        "X_train['word_density'] = X_train['char_count'] / (X_train['word_count']+1)\n",
        "X_train['punctuation_count'] = X_train['Review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
        "X_train['title_word_count'] = X_train['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
        "X_train['upper_case_word_count'] = X_train['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
        "\n",
        "\n",
        "X_test['char_count'] = X_test['Review'].apply(len)\n",
        "X_test['word_count'] = X_test['Review'].apply(lambda x: len(x.split()))\n",
        "X_test['word_density'] = X_test['char_count'] / (X_test['word_count']+1)\n",
        "X_test['punctuation_count'] = X_test['Review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
        "X_test['title_word_count'] = X_test['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
        "X_test['upper_case_word_count'] = X_test['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
        "\n",
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12896</th>\n",
              "      <td>Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....</td>\n",
              "      <td>268</td>\n",
              "      <td>52</td>\n",
              "      <td>5.056604</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13183</th>\n",
              "      <td>Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...</td>\n",
              "      <td>399</td>\n",
              "      <td>84</td>\n",
              "      <td>4.694118</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...</td>\n",
              "      <td>525</td>\n",
              "      <td>104</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...</td>\n",
              "      <td>203</td>\n",
              "      <td>35</td>\n",
              "      <td>5.638889</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13366</th>\n",
              "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...</td>\n",
              "      <td>295</td>\n",
              "      <td>51</td>\n",
              "      <td>5.673077</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                        Review  ...  upper_case_word_count\n",
              "12896  Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....  ...                      0\n",
              "13183  Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...  ...                      1\n",
              "1496   I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...  ...                      2\n",
              "5205   Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...  ...                      0\n",
              "13366  Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...  ...                      0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9DCvNRE87A8"
      },
      "source": [
        "# training a logistic regression model \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(C=1, random_state=42, solver='liblinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "mbi4X6_Y9FJB",
        "outputId": "7ddaf00f-90bf-459f-cfb0-3c5aa1094af4"
      },
      "source": [
        "# Model Evaluation\n",
        "lr.fit(X_train.drop(['Review'], axis=1), y_train)\n",
        "predictions = lr.predict(X_test.drop(['Review'], axis=1))\n",
        "\n",
        "print(classification_report(y_test, predictions))\n",
        "pd.DataFrame(confusion_matrix(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1271\n",
            "           1       0.78      1.00      0.87      4390\n",
            "\n",
            "    accuracy                           0.78      5661\n",
            "   macro avg       0.39      0.50      0.44      5661\n",
            "weighted avg       0.60      0.78      0.68      5661\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>4390</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1\n",
              "0  0  1271\n",
              "1  0  4390"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zvc4bwx9YkC"
      },
      "source": [
        "#### Features from sentiment analysis\n",
        "\n",
        "TextBlob is an excellent open-source library for performing NLP tasks with ease, including sentiment analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0s9J8959TR-",
        "outputId": "e5cf8b8e-42ff-43e2-abe8-47431eb99df0"
      },
      "source": [
        "import textblob\n",
        "\n",
        "textblob.TextBlob('This is an AMAZING pair of Jeans!').sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.7500000000000001, subjectivity=0.9)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn17LhYG9ddu"
      },
      "source": [
        "x_train_snt_obj = X_train['Review'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
        "X_train['Polarity'] = [obj.polarity for obj in x_train_snt_obj.values]\n",
        "X_train['Subjectivity'] = [obj.subjectivity for obj in x_train_snt_obj.values]\n",
        "\n",
        "x_test_snt_obj = X_test['Review'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
        "X_test['Polarity'] = [obj.polarity for obj in x_test_snt_obj.values]\n",
        "X_test['Subjectivity'] = [obj.subjectivity for obj in x_test_snt_obj.values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_X3LZJu5-IIC",
        "outputId": "b614e31d-333f-45d8-8749-83f019776679"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12896</th>\n",
              "      <td>Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....</td>\n",
              "      <td>268</td>\n",
              "      <td>52</td>\n",
              "      <td>5.056604</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.170455</td>\n",
              "      <td>0.490909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13183</th>\n",
              "      <td>Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...</td>\n",
              "      <td>399</td>\n",
              "      <td>84</td>\n",
              "      <td>4.694118</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.101944</td>\n",
              "      <td>0.719537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...</td>\n",
              "      <td>525</td>\n",
              "      <td>104</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.186538</td>\n",
              "      <td>0.458761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...</td>\n",
              "      <td>203</td>\n",
              "      <td>35</td>\n",
              "      <td>5.638889</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.825000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13366</th>\n",
              "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...</td>\n",
              "      <td>295</td>\n",
              "      <td>51</td>\n",
              "      <td>5.673077</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.329613</td>\n",
              "      <td>0.510268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                        Review  ...  Subjectivity\n",
              "12896  Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....  ...      0.490909\n",
              "13183  Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...  ...      0.719537\n",
              "1496   I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...  ...      0.458761\n",
              "5205   Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...  ...      0.825000\n",
              "13366  Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...  ...      0.510268\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "pQclpyfL-O_V",
        "outputId": "3dae0c42-f48d-44a1-cdec-55d19757bd61"
      },
      "source": [
        "# Model training and evaluation\n",
        "lr.fit(X_train.drop(['Review'], axis=1), y_train, )\n",
        "predictions = lr.predict(X_test.drop(['Review'], axis=1))\n",
        "\n",
        "print(classification_report(y_test, predictions))\n",
        "pd.DataFrame(confusion_matrix(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.27      0.38      1271\n",
            "           1       0.82      0.97      0.89      4390\n",
            "\n",
            "    accuracy                           0.81      5661\n",
            "   macro avg       0.75      0.62      0.64      5661\n",
            "weighted avg       0.79      0.81      0.77      5661\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>339</td>\n",
              "      <td>932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>153</td>\n",
              "      <td>4237</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1\n",
              "0  339   932\n",
              "1  153  4237"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajFl-OsF-3YG"
      },
      "source": [
        "#### Bag of word based feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJXL8Skf-gw_",
        "outputId": "b753cc64-2a65-429a-e187-52cde5ae5ec7"
      },
      "source": [
        "!pip install contractions\n",
        "!pip install textsearch\n",
        "!pip install tqdm\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.55)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.7/dist-packages (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch) (1.4.2)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch) (0.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyzA7CrD_Ags"
      },
      "source": [
        "# Text pre-processing and wrangling\n",
        "import nltk\n",
        "import contractions\n",
        "import re\n",
        "\n",
        "# remove some stopwords to capture negation in n-grams if possible\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "stop_words.remove('no')\n",
        "stop_words.remove('not')\n",
        "stop_words.remove('but')\n",
        "\n",
        "# load up a simple porter stemmer - nothing fancy\n",
        "ps = nltk.porter.PorterStemmer()\n",
        "\n",
        "def simple_text_preprocessor(document): \n",
        "    # lower case\n",
        "    document = str(document).lower()\n",
        "    \n",
        "    # expand contractions\n",
        "    document = contractions.fix(document)\n",
        "    \n",
        "    # remove unnecessary characters\n",
        "    document = re.sub(r'[^a-zA-Z]',r' ', document)\n",
        "    document = re.sub(r'nbsp', r'', document)\n",
        "    document = re.sub(' +', ' ', document)\n",
        "    \n",
        "    # simple porter stemming\n",
        "    document = ' '.join([ps.stem(word) for word in document.split()])\n",
        "    \n",
        "    # stopwords removal\n",
        "    document = ' '.join([word for word in document.split() if word not in stop_words])\n",
        "    \n",
        "    return document\n",
        "\n",
        "stp = np.vectorize(simple_text_preprocessor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0_adKaBl_Ogs",
        "outputId": "8360e447-b628-49de-b744-8d9c8159574c"
      },
      "source": [
        "X_train['Clean Review'] = stp(X_train['Review'].values)\n",
        "X_test['Clean Review'] = stp(X_test['Review'].values)\n",
        "\n",
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>Clean Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12896</th>\n",
              "      <td>Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....</td>\n",
              "      <td>268</td>\n",
              "      <td>52</td>\n",
              "      <td>5.056604</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.170455</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>soooo soft thi delight soft fluffi sweater might bought store petit size white wa pretti good weight not light heavi comfort would fun layer variou outfit not seem would</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13183</th>\n",
              "      <td>Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...</td>\n",
              "      <td>399</td>\n",
              "      <td>84</td>\n",
              "      <td>4.694118</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.101944</td>\n",
              "      <td>0.719537</td>\n",
              "      <td>eye thi but dind get final visit store petit thi dress wa cours snag tri love color mean awesom fabric also veri soft but cut wa huh noth go rave think would nice casual day but often wear jogger ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...</td>\n",
              "      <td>525</td>\n",
              "      <td>104</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.186538</td>\n",
              "      <td>0.458761</td>\n",
              "      <td>want like thi want like thi top badli badli fact first size not fit order two size make sure xl l none work realli want like thi top onlin photo make cloth look flatter shirt not least shirt onlin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...</td>\n",
              "      <td>203</td>\n",
              "      <td>35</td>\n",
              "      <td>5.638889</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>beauti blous bought thi daughter law birthday beauti feminin design well made nice fabric wear thi work lunch even veri versatil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13366</th>\n",
              "      <td>Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...</td>\n",
              "      <td>295</td>\n",
              "      <td>51</td>\n",
              "      <td>5.673077</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.329613</td>\n",
              "      <td>0.510268</td>\n",
              "      <td>boxi larg boxi unflatt larg I curvi pound thi top size swallow no shape materi not feel great either would not even purchas sale graphic tee much nicer I stick splendid sundri</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                        Review  ...                                                                                                                                                                                             Clean Review\n",
              "12896  Soooo soft! This is a delightfully soft and fluffy sweater. i might have bought it if my store had the petite size. the white was pretty and a good weight (not too light or heavy) and comfortable....  ...                                soooo soft thi delight soft fluffi sweater might bought store petit size white wa pretti good weight not light heavi comfort would fun layer variou outfit not seem would\n",
              "13183  Had my eye on this, but dind't get I finally visited a store with petite, and this dress was there, so of course, i snagged it to try on... i love the colors, i mean awesome, the fabric is also ve...  ...  eye thi but dind get final visit store petit thi dress wa cours snag tri love color mean awesom fabric also veri soft but cut wa huh noth go rave think would nice casual day but often wear jogger ...\n",
              "1496   I wanted to like this... I wanted to like this top so so so so badly. so badly in fact, that after the first size didn't fit, i ordered two other sizes to make sure: xl, l, m. none of them worked ...  ...  want like thi want like thi top badli badli fact first size not fit order two size make sure xl l none work realli want like thi top onlin photo make cloth look flatter shirt not least shirt onlin...\n",
              "5205   Beautiful blouse Bought this for my daughter in law's birthday. it's just a beautiful, feminine design, well made, nice fabric.. she can wear this for work or for lunch or an evening out. very ver...  ...                                                                         beauti blous bought thi daughter law birthday beauti feminin design well made nice fabric wear thi work lunch even veri versatil\n",
              "13366  Boxy. large. Boxy, unflattering, and large.\\n\\ni'm 5'2'' and a curvy 135 pounds. this top (size s) swallowed me, had no shape, and the material didn't feel great either. i wouldn't even purchase i...  ...                          boxi larg boxi unflatt larg I curvi pound thi top size swallow no shape materi not feel great either would not even purchas sale graphic tee much nicer I stick splendid sundri\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "h2Go_0ZA_T4l",
        "outputId": "e40333c1-bb9c-4683-e43b-ec75ab3b7ba3"
      },
      "source": [
        "# Extracting out the structured features\n",
        "\n",
        "X_train_metadata = X_train.drop(['Review', 'Clean Review'], axis=1).reset_index(drop=True)\n",
        "X_test_metadata = X_test.drop(['Review', 'Clean Review'], axis=1).reset_index(drop=True)\n",
        "\n",
        "X_train_metadata.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>268</td>\n",
              "      <td>52</td>\n",
              "      <td>5.056604</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.170455</td>\n",
              "      <td>0.490909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>399</td>\n",
              "      <td>84</td>\n",
              "      <td>4.694118</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.101944</td>\n",
              "      <td>0.719537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>525</td>\n",
              "      <td>104</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.186538</td>\n",
              "      <td>0.458761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>203</td>\n",
              "      <td>35</td>\n",
              "      <td>5.638889</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.825000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>295</td>\n",
              "      <td>51</td>\n",
              "      <td>5.673077</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.329613</td>\n",
              "      <td>0.510268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   char_count  word_count  ...  Polarity  Subjectivity\n",
              "0         268          52  ...  0.170455      0.490909\n",
              "1         399          84  ...  0.101944      0.719537\n",
              "2         525         104  ...  0.186538      0.458761\n",
              "3         203          35  ...  0.625000      0.825000\n",
              "4         295          51  ...  0.329613      0.510268\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "XnkGA3f7_uaD",
        "outputId": "ce2c587b-67b0-44f4-a91b-4d842179ffa9"
      },
      "source": [
        "# create text representation model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1, 1))\n",
        "X_traincv = cv.fit_transform(X_train['Clean Review']).toarray()\n",
        "X_traincv = pd.DataFrame(X_traincv, columns=cv.get_feature_names())\n",
        "\n",
        "X_testcv = cv.transform(X_test['Clean Review']).toarray()\n",
        "X_testcv = pd.DataFrame(X_testcv, columns=cv.get_feature_names())\n",
        "X_traincv.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>aaaaandidon</th>\n",
              "      <th>aaaaannnnnnd</th>\n",
              "      <th>aaaah</th>\n",
              "      <th>aaaahmaz</th>\n",
              "      <th>aaah</th>\n",
              "      <th>ab</th>\n",
              "      <th>abbey</th>\n",
              "      <th>abbi</th>\n",
              "      <th>abck</th>\n",
              "      <th>abdomen</th>\n",
              "      <th>abdomin</th>\n",
              "      <th>abercrombi</th>\n",
              "      <th>abil</th>\n",
              "      <th>abject</th>\n",
              "      <th>abl</th>\n",
              "      <th>abnorm</th>\n",
              "      <th>abo</th>\n",
              "      <th>abolut</th>\n",
              "      <th>abou</th>\n",
              "      <th>abov</th>\n",
              "      <th>abroad</th>\n",
              "      <th>abruptli</th>\n",
              "      <th>abso</th>\n",
              "      <th>absolut</th>\n",
              "      <th>absolutley</th>\n",
              "      <th>absolutli</th>\n",
              "      <th>absorb</th>\n",
              "      <th>abstract</th>\n",
              "      <th>absurd</th>\n",
              "      <th>abt</th>\n",
              "      <th>abund</th>\n",
              "      <th>abus</th>\n",
              "      <th>ac</th>\n",
              "      <th>acacia</th>\n",
              "      <th>accent</th>\n",
              "      <th>accentu</th>\n",
              "      <th>accentuatea</th>\n",
              "      <th>accept</th>\n",
              "      <th>acceptabl</th>\n",
              "      <th>...</th>\n",
              "      <th>yoga</th>\n",
              "      <th>yogi</th>\n",
              "      <th>yogini</th>\n",
              "      <th>yoke</th>\n",
              "      <th>yolk</th>\n",
              "      <th>yoo</th>\n",
              "      <th>yore</th>\n",
              "      <th>york</th>\n",
              "      <th>yoself</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youth</th>\n",
              "      <th>youthful</th>\n",
              "      <th>yr</th>\n",
              "      <th>yuck</th>\n",
              "      <th>yucki</th>\n",
              "      <th>yuk</th>\n",
              "      <th>yum</th>\n",
              "      <th>yumi</th>\n",
              "      <th>yummi</th>\n",
              "      <th>yummiest</th>\n",
              "      <th>yummysweat</th>\n",
              "      <th>yup</th>\n",
              "      <th>zag</th>\n",
              "      <th>zara</th>\n",
              "      <th>zermatt</th>\n",
              "      <th>zero</th>\n",
              "      <th>zig</th>\n",
              "      <th>zigzag</th>\n",
              "      <th>zillion</th>\n",
              "      <th>zing</th>\n",
              "      <th>zip</th>\n",
              "      <th>zipper</th>\n",
              "      <th>zipperi</th>\n",
              "      <th>zippi</th>\n",
              "      <th>zone</th>\n",
              "      <th>zooland</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zowi</th>\n",
              "      <th>zuma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 8554 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   aa  aaaaandidon  aaaaannnnnnd  aaaah  ...  zooland  zoom  zowi  zuma\n",
              "0   0            0             0      0  ...        0     0     0     0\n",
              "1   0            0             0      0  ...        0     0     0     0\n",
              "2   0            0             0      0  ...        0     0     0     0\n",
              "3   0            0             0      0  ...        0     0     0     0\n",
              "4   0            0             0      0  ...        0     0     0     0\n",
              "\n",
              "[5 rows x 8554 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "ztFpTUhX_1Fk",
        "outputId": "8001f4c3-e4dc-46e8-c1ed-5319a91e0dc6"
      },
      "source": [
        "X_train_comb = pd.concat([X_train_metadata, X_traincv], axis=1)\n",
        "X_test_comb = pd.concat([X_test_metadata, X_testcv], axis=1)\n",
        "\n",
        "X_train_comb.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>punctuation_count</th>\n",
              "      <th>title_word_count</th>\n",
              "      <th>upper_case_word_count</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>aa</th>\n",
              "      <th>aaaaandidon</th>\n",
              "      <th>aaaaannnnnnd</th>\n",
              "      <th>aaaah</th>\n",
              "      <th>aaaahmaz</th>\n",
              "      <th>aaah</th>\n",
              "      <th>ab</th>\n",
              "      <th>abbey</th>\n",
              "      <th>abbi</th>\n",
              "      <th>abck</th>\n",
              "      <th>abdomen</th>\n",
              "      <th>abdomin</th>\n",
              "      <th>abercrombi</th>\n",
              "      <th>abil</th>\n",
              "      <th>abject</th>\n",
              "      <th>abl</th>\n",
              "      <th>abnorm</th>\n",
              "      <th>abo</th>\n",
              "      <th>abolut</th>\n",
              "      <th>abou</th>\n",
              "      <th>abov</th>\n",
              "      <th>abroad</th>\n",
              "      <th>abruptli</th>\n",
              "      <th>abso</th>\n",
              "      <th>absolut</th>\n",
              "      <th>absolutley</th>\n",
              "      <th>absolutli</th>\n",
              "      <th>absorb</th>\n",
              "      <th>abstract</th>\n",
              "      <th>absurd</th>\n",
              "      <th>abt</th>\n",
              "      <th>abund</th>\n",
              "      <th>...</th>\n",
              "      <th>yoga</th>\n",
              "      <th>yogi</th>\n",
              "      <th>yogini</th>\n",
              "      <th>yoke</th>\n",
              "      <th>yolk</th>\n",
              "      <th>yoo</th>\n",
              "      <th>yore</th>\n",
              "      <th>york</th>\n",
              "      <th>yoself</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youth</th>\n",
              "      <th>youthful</th>\n",
              "      <th>yr</th>\n",
              "      <th>yuck</th>\n",
              "      <th>yucki</th>\n",
              "      <th>yuk</th>\n",
              "      <th>yum</th>\n",
              "      <th>yumi</th>\n",
              "      <th>yummi</th>\n",
              "      <th>yummiest</th>\n",
              "      <th>yummysweat</th>\n",
              "      <th>yup</th>\n",
              "      <th>zag</th>\n",
              "      <th>zara</th>\n",
              "      <th>zermatt</th>\n",
              "      <th>zero</th>\n",
              "      <th>zig</th>\n",
              "      <th>zigzag</th>\n",
              "      <th>zillion</th>\n",
              "      <th>zing</th>\n",
              "      <th>zip</th>\n",
              "      <th>zipper</th>\n",
              "      <th>zipperi</th>\n",
              "      <th>zippi</th>\n",
              "      <th>zone</th>\n",
              "      <th>zooland</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zowi</th>\n",
              "      <th>zuma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>268</td>\n",
              "      <td>52</td>\n",
              "      <td>5.056604</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.170455</td>\n",
              "      <td>0.490909</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>399</td>\n",
              "      <td>84</td>\n",
              "      <td>4.694118</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.101944</td>\n",
              "      <td>0.719537</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>525</td>\n",
              "      <td>104</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.186538</td>\n",
              "      <td>0.458761</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>203</td>\n",
              "      <td>35</td>\n",
              "      <td>5.638889</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>295</td>\n",
              "      <td>51</td>\n",
              "      <td>5.673077</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.329613</td>\n",
              "      <td>0.510268</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 8562 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   char_count  word_count  word_density  ...  zoom  zowi  zuma\n",
              "0         268          52      5.056604  ...     0     0     0\n",
              "1         399          84      4.694118  ...     0     0     0\n",
              "2         525         104      5.000000  ...     0     0     0\n",
              "3         203          35      5.638889  ...     0     0     0\n",
              "4         295          51      5.673077  ...     0     0     0\n",
              "\n",
              "[5 rows x 8562 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "8Jm_Qb0E_4hO",
        "outputId": "e75701e4-cfd1-4082-ac98-98ef76cce012"
      },
      "source": [
        "# model training and evaluation\n",
        "\n",
        "lr.fit(X_train_comb, y_train)\n",
        "predictions = lr.predict(X_test_comb)\n",
        "\n",
        "print(classification_report(y_test, predictions))\n",
        "pd.DataFrame(confusion_matrix(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.70      0.73      1271\n",
            "           1       0.92      0.94      0.93      4390\n",
            "\n",
            "    accuracy                           0.88      5661\n",
            "   macro avg       0.84      0.82      0.83      5661\n",
            "weighted avg       0.88      0.88      0.88      5661\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>895</td>\n",
              "      <td>376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>285</td>\n",
              "      <td>4105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0     1\n",
              "0  895   376\n",
              "1  285  4105"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9B0-aOBAD-H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p65_xKVCA4I7"
      },
      "source": [
        "#### Classification Model Workflow\n",
        "1. Text Normalization\n",
        "2. Feature Engineering\n",
        "3. Dimension Reduction\n",
        "4. Supervised Learning\n",
        "5. Model Evaluation"
      ]
    }
  ]
}