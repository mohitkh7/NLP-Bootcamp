{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dphi_sarcastic_headline_classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO6+qu8n4vjjOPRm6Kdb3Nc"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tlUkDx_rAr8"
      },
      "source": [
        "# Sarcasm Prediction\n",
        "\n",
        "Dataset contains news headlines - which are aimed to be written in a sarcastic manner by the news author. The task is to build our NLP models and predict whether the headline is sarcastic or not.\n",
        "\n",
        "**About the Data**\n",
        "\n",
        "Each record of dataset consists of two attributes:\n",
        "\n",
        "- is_sarcastic: 1 if the record is sarcastic otherwise 0. This is the target variable.\n",
        "\n",
        "- headline: this is the headline of the news article\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm3DIOPeq1nU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a516e0b1-d13c-4474-f59d-9b5fa593cc0c"
      },
      "source": [
        "# Setup drive for colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0TsAjQVEGen"
      },
      "source": [
        "## Install dependecies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywX7pM8AEGJb",
        "outputId": "4a23de4e-2a2b-4969-fc26-e13e9e00605f"
      },
      "source": [
        "!pip install contractions\n",
        "!pip install textsearch\n",
        "!pip install tqdm\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.0.55-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 15.4 MB/s \n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
            "\u001b[K     |████████████████████████████████| 284 kB 65.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85435 sha256=4dafead148e17709070aed89d010a71d5a61d24c5ed5f8a213d3da025cad17d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.0 contractions-0.0.55 pyahocorasick-1.4.2 textsearch-0.0.21\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.7/dist-packages (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch) (1.4.2)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch) (0.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTNIwO0dEcE4"
      },
      "source": [
        "import contractions\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZBIVREnr4l_"
      },
      "source": [
        "## Load and view dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "bQxJgS9krwCP",
        "outputId": "685733cc-ecf4-43bb-e95f-f4c1dcfff227"
      },
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/dphi_dataset/dphi_nlp_sarcastic_headline_train.csv')\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hungover man horrified to learn he made dozens...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>emily's list founder: women are the 'problem s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>send your kids back to school with confidence</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>watch: experts talk pesticides and health</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  is_sarcastic\n",
              "0  supreme court votes 7-2 to legalize all worldl...             1\n",
              "1  hungover man horrified to learn he made dozens...             1\n",
              "2  emily's list founder: women are the 'problem s...             0\n",
              "3      send your kids back to school with confidence             0\n",
              "4          watch: experts talk pesticides and health             0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_FNn6GB4MoN"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRDS6kjMsHBC",
        "outputId": "01b9ff8a-06e3-4851-fea2-d44e2a014ffc"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44262, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inWiphZP4Sm7",
        "outputId": "5676aaf3-b33a-4fad-df01-d63de71fc94f"
      },
      "source": [
        "train_data.isna().count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "headline        44262\n",
              "is_sarcastic    44262\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Roh4I6Iz4w2e",
        "outputId": "c1846beb-2074-4b3f-fb19-b5c80290f473"
      },
      "source": [
        "train_data['is_sarcastic'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    23958\n",
              "1    20304\n",
              "Name: is_sarcastic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M07OqMMD47tK"
      },
      "source": [
        "From the EDA we can conclude we have 44262 samples out of which 20304 are sarcastic records and rest are non-sarcastic headlines. There is no null value in entire dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNMTr7u15Khl"
      },
      "source": [
        "## Text Wrangling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAAQaiNY422-"
      },
      "source": [
        "# Text pre-processing and wrangling\n",
        "\n",
        "# remove some stopwords to capture negation in n-grams if possible\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# load up a simple porter stemmer - nothing fancy\n",
        "ps = nltk.porter.PorterStemmer()\n",
        "\n",
        "def text_preprocessor(document): \n",
        "    # lower case\n",
        "    document = str(document).lower()\n",
        "    \n",
        "    # expand contractions\n",
        "    document = contractions.fix(document)\n",
        "    \n",
        "    # remove unnecessary characters\n",
        "    document = re.sub(r'[^a-zA-Z]',r' ', document)\n",
        "    document = re.sub(r'nbsp', r'', document)\n",
        "    document = re.sub(' +', ' ', document)\n",
        "    \n",
        "    # simple porter stemming\n",
        "    document = ' '.join([ps.stem(word) for word in document.split()])\n",
        "    \n",
        "    # stopwords removal\n",
        "    document = ' '.join([word for word in document.split() if word not in stop_words])\n",
        "    \n",
        "    return document\n",
        "\n",
        "clean_text = np.vectorize(text_preprocessor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oe01sANIUYl"
      },
      "source": [
        "def get_freq_words(data, n=2000):\n",
        "  word_freq = Counter()\n",
        "\n",
        "  for heading in data['clean_headline'].values:\n",
        "    word_freq.update(heading.split())\n",
        "  print(word_freq[n])\n",
        "  most_freq_words = set()\n",
        "  for word, freq in word_freq.most_common(n):\n",
        "    most_freq_words.add(word)\n",
        "  \n",
        "  return most_freq_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM-CdpatFzM7"
      },
      "source": [
        "def text_postprocessor(document, most_freq_words):\n",
        "  document = ' '.join([word for word in document.split() if word in most_freq_words])\n",
        "  return document\n",
        "parse_freq_words = np.vectorize(text_postprocessor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoDxXjmjGbfo"
      },
      "source": [
        "def text_wrangling(data, freq_words, n=2000):\n",
        "  data['clean_headline'] = clean_text(data['headline'].values)\n",
        "  if freq_words is None:\n",
        "    freq_words = get_freq_words(data, n)\n",
        "  print(len(freq_words))\n",
        "  data['main_headline'] = parse_freq_words(data['clean_headline'].values, freq_words)\n",
        "  return freq_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "h06VVtwJKvHZ",
        "outputId": "c6840cbe-468a-4e68-d2e7-21346a71744d"
      },
      "source": [
        "freq_words_set = text_wrangling(train_data, None, 5000)\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>clean_headline</th>\n",
              "      <th>main_headline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
              "      <td>1</td>\n",
              "      <td>suprem court vote legal worldli vice</td>\n",
              "      <td>suprem court vote legal vice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hungover man horrified to learn he made dozens...</td>\n",
              "      <td>1</td>\n",
              "      <td>hungov man horrifi learn made dozen plan last ...</td>\n",
              "      <td>hungov man horrifi learn made dozen plan last ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>emily's list founder: women are the 'problem s...</td>\n",
              "      <td>0</td>\n",
              "      <td>emili list founder women problem solver congress</td>\n",
              "      <td>list founder women problem congress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>send your kids back to school with confidence</td>\n",
              "      <td>0</td>\n",
              "      <td>send kid back school confid</td>\n",
              "      <td>send kid back school confid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>watch: experts talk pesticides and health</td>\n",
              "      <td>0</td>\n",
              "      <td>watch expert talk pesticid health</td>\n",
              "      <td>watch expert talk health</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  ...                                      main_headline\n",
              "0  supreme court votes 7-2 to legalize all worldl...  ...                       suprem court vote legal vice\n",
              "1  hungover man horrified to learn he made dozens...  ...  hungov man horrifi learn made dozen plan last ...\n",
              "2  emily's list founder: women are the 'problem s...  ...                list founder women problem congress\n",
              "3      send your kids back to school with confidence  ...                        send kid back school confid\n",
              "4          watch: experts talk pesticides and health  ...                           watch expert talk health\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "122l1ryc_Bud"
      },
      "source": [
        "## Bag of words text representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMEHmF7h-kfw"
      },
      "source": [
        "# create text representation model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def get_bag_of_words(data):\n",
        "  cv = CountVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1, 1))\n",
        "  bag_of_words = cv.fit_transform(data['main_headline']).toarray()\n",
        "  return pd.DataFrame(bag_of_words, columns=cv.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0HPUYbK8QVn",
        "outputId": "d21c76f7-6075-456e-8101-be498d234bdb"
      },
      "source": [
        "train_data_cv = get_bag_of_words(train_data)\n",
        "train_data_cv.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44262, 4982)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQv75c_95MV5"
      },
      "source": [
        "## Appyling Logistic Regression ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWm4gBQ18mys"
      },
      "source": [
        "# Train-Test Split\n",
        "X_train, X_test = train_data_cv[:32000], train_data_cv[32000:]\n",
        "Y_train, Y_test = train_data['is_sarcastic'][:32000], train_data['is_sarcastic'][32000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "bRcEFou9CbqT",
        "outputId": "ccd212cb-c9df-4afd-802b-05a0742019da"
      },
      "source": [
        "# model training and evaluation\n",
        "lr = LogisticRegression(C=1, random_state=42, solver='liblinear')\n",
        "\n",
        "lr.fit(X_train, Y_train)\n",
        "predictions = lr.predict(X_test)\n",
        "\n",
        "print(classification_report(Y_test, predictions))\n",
        "pd.DataFrame(confusion_matrix(Y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.86      0.84      6596\n",
            "           1       0.83      0.79      0.81      5666\n",
            "\n",
            "    accuracy                           0.83     12262\n",
            "   macro avg       0.83      0.83      0.83     12262\n",
            "weighted avg       0.83      0.83      0.83     12262\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5682</td>\n",
              "      <td>914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1173</td>\n",
              "      <td>4493</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1\n",
              "0  5682   914\n",
              "1  1173  4493"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmR3_4CKdB2F"
      },
      "source": [
        "Hence we conclude to use Logistic regression ML algorithm on bag of words representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey2wXHZNZ0LU"
      },
      "source": [
        "## Predicting on actual test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61D3VjP8-Oki"
      },
      "source": [
        "### Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtDLw2r6HYqy"
      },
      "source": [
        "# loading training and test data\n",
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/dphi_dataset/dphi_nlp_sarcastic_headline_train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/dphi_dataset/dphi_nlp_sarcastic_headline_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCkYfosb-ttA"
      },
      "source": [
        "### Wrangling data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i39hbQu-vwH"
      },
      "source": [
        "freq_words_set = text_wrangling(train_data, None, 2000)\n",
        "text_wrangling(test_data, freq_words_set, 2000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8Q6C_O9JGju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba84ba2f-a191-4621-b9e0-7d44872cd18b"
      },
      "source": [
        "train_data_cv = get_bag_of_words(train_data)\n",
        "test_data_cv = get_bag_of_words(test_data)\n",
        "\n",
        "print(train_data_cv.shape, test_data_cv.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(44262, 1983) (11066, 1983)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QmC7MVKAJA-"
      },
      "source": [
        "# generate prediction\n",
        "lr = LogisticRegression(C=1, random_state=42, solver='liblinear')\n",
        "\n",
        "lr.fit(train_data_cv, train_data['is_sarcastic'])\n",
        "predictions = lr.predict(test_data_cv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1kIEPdCJl58"
      },
      "source": [
        "### Write output to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "stwCNYmj_oX7",
        "outputId": "265bda80-4816-44af-c290-bebd49beb199"
      },
      "source": [
        "test_data['prediction'] = predictions\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>clean_headline</th>\n",
              "      <th>main_headline</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>area stand-up comedian questions the deal with...</td>\n",
              "      <td>area stand comedian question deal drive thru w...</td>\n",
              "      <td>area stand comedian question deal drive window</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dozens of glowing exit signs mercilessly taunt...</td>\n",
              "      <td>dozen glow exit sign mercilessli taunt multipl...</td>\n",
              "      <td>dozen exit sign employe</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>perfect response to heckler somewhere in prop ...</td>\n",
              "      <td>perfect respons heckler somewher prop comedian...</td>\n",
              "      <td>perfect respons comedian</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gop prays for ossoff lossoff</td>\n",
              "      <td>gop pray ossoff lossoff</td>\n",
              "      <td>gop</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>trevor noah says the scary truth about trump's...</td>\n",
              "      <td>trevor noah say scari truth trump rumor love c...</td>\n",
              "      <td>trevor noah say truth trump love child</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  ... prediction\n",
              "0  area stand-up comedian questions the deal with...  ...          1\n",
              "1  dozens of glowing exit signs mercilessly taunt...  ...          1\n",
              "2  perfect response to heckler somewhere in prop ...  ...          0\n",
              "3                       gop prays for ossoff lossoff  ...          0\n",
              "4  trevor noah says the scary truth about trump's...  ...          0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPk0pMwMAt9k"
      },
      "source": [
        "output_df = test_data[['prediction']]\n",
        "output_df.to_csv('/content/drive/MyDrive/dphi_dataset/dphi_nlp_sarcastic_headline_output.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3J6O1u7BQCi",
        "outputId": "14ca6747-7e04-466e-f0f8-3fd22abe9c2b"
      },
      "source": [
        "test_data['prediction'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6375\n",
              "1    4691\n",
              "Name: prediction, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0zunvTMB0Fy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}